{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1458e6",
   "metadata": {},
   "source": [
    "# Breast Cancer Prevision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79537b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, our goal is to build a classification model based in Logistic Regression. We are going to talk more about Logistic Regression soon. For now, let's focus in the main aspects of the analysis.\n",
    "\n",
    "This breast cancer database was obtained from the University of Wisconsin Hospitals. All the details about the research that generated this data can be found in the following link: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29.\n",
    "\n",
    "## Attribute Information\n",
    "\n",
    "The dataset is composed by 11 columns and 699 rows. Each row is related with some patient while each column represents some tumor attribute, except the first one named 'id number', that will be not relevant for our analysis. \n",
    "\n",
    "1. Sample code number: id number\n",
    "2. Clump Thickness: 1 - 10\n",
    "3. Uniformity of Cell Size: 1 - 10\n",
    "4. Uniformity of Cell Shape: 1 - 10\n",
    "5. Marginal Adhesion: 1 - 10\n",
    "6. Single Epithelial Cell Size: 1 - 10\n",
    "7. Bare Nuclei: 1 - 10\n",
    "8. Bland Chromatin: 1 - 10\n",
    "9. Normal Nucleoli: 1 - 10\n",
    "10. Mitoses: 1 - 10\n",
    "11. Class: (2 for benign, 4 for malignant)\n",
    "\n",
    "In the 11th column we have the results for the nature of the tumor: 2 for benign and 4 for malignant. Our goal here is to build a machine learning model that will predict the nature of the tumor based in the nine characteristics cited in the list above. The range of such characteristics, let's call then variables from now on, goes from 1 to 10. We are not going the deep in the medicinal details related to these variables, however, these nine parameters will be the dependent variables of our classification model. \n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6bdd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "#pd.set_option('display.max_columns', 20)\n",
    "#pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180eac07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  V10\n",
       "0    1000025   5   1   1   1   2   1   3   1   1    2\n",
       "1    1002945   5   4   4   5   7  10   3   2   1    2\n",
       "2    1015425   3   1   1   1   2   2   3   1   1    2\n",
       "3    1016277   6   8   8   1   3   4   3   7   1    2\n",
       "4    1017023   4   1   1   3   2   1   3   1   1    2\n",
       "..       ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...\n",
       "694   776715   3   1   1   1   3   2   1   1   1    2\n",
       "695   841769   2   1   1   1   2   1   1   1   1    2\n",
       "696   888820   5  10  10   3   7   3   8  10   2    4\n",
       "697   897471   4   8   6   4   3   4  10   6   1    4\n",
       "698   897471   4   8   8   5   4   5  10   4   1    4\n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['ID', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10']\n",
    "dataset = pd.read_table('breast-cancer-wisconsin.data', sep=',', names=index)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4114e7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      int64\n",
       "V1      int64\n",
       "V2      int64\n",
       "V3      int64\n",
       "V4      int64\n",
       "V5      int64\n",
       "V6     object\n",
       "V7      int64\n",
       "V8      int64\n",
       "V9      int64\n",
       "V10     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b42aa1",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "The dataset is almost ready, unless for one detail... The problem seems to be in column V6 where there are mixed data. Then, our fist task is to eliminate these problematic values in V6.\n",
    "\n",
    "Let's start figuring out what are the problematic cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4372eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 ?\n",
      "40 ?\n",
      "139 ?\n",
      "145 ?\n",
      "158 ?\n",
      "164 ?\n",
      "235 ?\n",
      "249 ?\n",
      "275 ?\n",
      "292 ?\n",
      "294 ?\n",
      "297 ?\n",
      "315 ?\n",
      "321 ?\n",
      "411 ?\n",
      "617 ?\n",
      "Number of problematic cells: 16\n"
     ]
    }
   ],
   "source": [
    "aux_list = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "counter = 0\n",
    "for index, value in dataset['V6'].items():\n",
    "    if value in aux_list:\n",
    "        pass\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(index, value)\n",
    "\n",
    "print(f'Number of problematic cells: {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129a6c2",
   "metadata": {},
   "source": [
    "Because of 16 cells our dataset wasn't ready. These cells have the question mark symbol '?' that can't be interpreted as an integer. These 16 rows corresponds to less that 2,3 % of the dataset. Once this percentage is quite small, we'll just drop these problematic columns. The remain amount of data will be enough for our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5626204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in dataset['V6'].items():\n",
    "    if value == '?':\n",
    "        dataset.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a11220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID     int64\n",
       "V1     int64\n",
       "V2     int64\n",
       "V3     int64\n",
       "V4     int64\n",
       "V5     int64\n",
       "V6     int64\n",
       "V7     int64\n",
       "V8     int64\n",
       "V9     int64\n",
       "V10    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['V6'] = dataset['V6'].astype(int)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e41cde",
   "metadata": {},
   "source": [
    "Now the dataset is ready for the implementation of our logistic regression model. However, before we start the code implementation, a fast digression about logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d37353",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Assume that there are two freshman students in physics and that the semi annual calculus exam is coming. The first student is being very dedicated in the studies while the second one not that much, but he is studying a bit. So the question is which student is most likely to pass the test? \n",
    "\n",
    "Perhaps you are presuming that the second student certainly will fail while the first one certainly will pass. If it is true, unfortunately we'll need to disagree. Both students have chance to pass the exam, however, the probability of the first one is going to pass is greater than of the second one. \n",
    "\n",
    "Logistic Regression handles this kind of situation. Essentialy, considering the single variable case, let's call such variable x, a Logistic Regression model will provide to us a YES or NO type answer based on the value of x. The model also provides the probability of the YES or NO answer happens. For example, if the probability of the first student pass in the exam is 95 %, it's most likely that our model will provide the answer YES for this student. Still in exam exemple, x could be the hours of study performed by a student. \n",
    "\n",
    "The Logistic Regression is based in the Logistic Function (or Sigmoid's Function):\n",
    "\n",
    "$$f(x)=\\frac{L}{1+e^{-k(x-x_{0})}},$$\n",
    "\n",
    "where $x_{0}$ is the value of the Sigmoid's midpoint, $L$ is the curve's maximum value and $k$ is the logistic growth rate or steepness of the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d33951a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "u = np.linspace(-15, 15, 100) \n",
    "\n",
    "def logistic(u):\n",
    "    return 1/(1 + np.exp(-0.5*(u-1)))\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'darkred',\n",
    "        'weight': 'normal',\n",
    "        'size': 14,\n",
    "        }\n",
    "\n",
    "f = logistic(u)\n",
    "plt.plot(u, f) \n",
    "plt.xlabel(\"$x$\", fontdict=font) \n",
    "plt.ylabel(\"$f(x)$\", fontdict=font)\n",
    "plt.title('Logistic Function: L = 1, k = 0.5, $x_0$ = 1')\n",
    "plt.axhline(y=1, color='r', linestyle='--')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6213d",
   "metadata": {},
   "source": [
    "The figure right above is an example of Logistic Function. Now it becomes clearer why this Logistic Regression model is useful for classification models. In the context of calculus exam exemple, a student with few hours of study will probably not pass the exam. However, from some hours of study, this probability starts to increase until reach the value of 1 (100 %). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ad3d7",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ab0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,1:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed230229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c42d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdafff7d",
   "metadata": {},
   "source": [
    "The classification model is ready! We are now capeble to predict if a tumor is benign or malignant by the **prediction** function which take some row from the test dataset (information about some patient) and makes the prevision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f29d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(index):\n",
    "    vec = x_test[index]\n",
    "    result = classifier.predict([vec])\n",
    "    if result == [2]:\n",
    "        return print('The tumor is benign.')\n",
    "    else:\n",
    "        return print('The tumor is malignant.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f25be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tumor is benign.\n",
      "The tumor is benign.\n",
      "The tumor is malignant.\n",
      "The tumor is malignant.\n",
      "The tumor is benign.\n",
      "The tumor is benign.\n",
      "The tumor is benign.\n",
      "The tumor is malignant.\n"
     ]
    }
   ],
   "source": [
    "for index in range(8):\n",
    "    prediction(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f851d",
   "metadata": {},
   "source": [
    "## Accuracy of our classification\n",
    "\n",
    "Above we computed confusion matrix, which is one of the classification metrics that evaluates the accuracy of a classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f97c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  3]\n",
      " [ 3 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2bd8f",
   "metadata": {},
   "source": [
    "The confusion matrix essentialy provides to us the match between our classification model and the real results. The diagonal elements of the matrix are the cases where both the prevision and the real observations matched. The off-diagonal terms are the opposite: cases where the prevision and the real observation don't agree.\n",
    "\n",
    "It's easy to compute the accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0003b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is 95.62043795620438.\n"
     ]
    }
   ],
   "source": [
    "acc = ((cm[0,0]+cm[1,1])/(cm[0,0]+cm[1,1]+cm[0,1]+cm[1,0]))*100\n",
    "print(f'The accuracy of our model is {acc}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1d05e",
   "metadata": {},
   "source": [
    "Of course the accuracy computed above is a great indicative that our classification model is working very well. However, we need to submit our classification model to a more exigent test of validation. \n",
    "\n",
    "This test is named **k-fold cross-validation** ($k$-fold CV). Basically, the training set is split into k smaller sets, let's name these splits as k-folds. Once the splits were done, the model is trained using $k-1$ folds as training data. The resulting model is validated by the remaining part of the data, i.e., the fold that was \"ignored\" before is used as a test set to compute a performance measure, such as accuracy.\n",
    "\n",
    "We will perform the $k$-fold CV setting $k=10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6800ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94545455 0.96363636 0.96363636 1.         0.94545455 1.\n",
      " 0.96296296 0.96296296 0.98148148 0.94444444]\n",
      "The mean accuracy is 0.967003367003367\n",
      "The standard deviation for the accuracies is 0.019697976894447813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(classifier, X=x_train, y=y_train, cv=10)\n",
    "\n",
    "print(accuracies)\n",
    "print('The mean accuracy is {}'.format(accuracies.mean()))\n",
    "print('The standard deviation for the accuracies is {}'.format(accuracies.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716d0f2",
   "metadata": {},
   "source": [
    "After the $k$-fold CV we obtained a really good accuracy for all the 10 tests. The main accuracy is also very good as well as the standard deviation that is pretty small. Seems that our classification model is working fine!\n",
    "\n",
    "That is all for today. I hope you enjoyed this study of case. See you next time! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
